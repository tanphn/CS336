{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install einops\n!pip install sentence_transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:25:45.835052Z","iopub.execute_input":"2024-12-25T04:25:45.835420Z","iopub.status.idle":"2024-12-25T04:25:54.103725Z","shell.execute_reply.started":"2024-12-25T04:25:45.835377Z","shell.execute_reply":"2024-12-25T04:25:54.102955Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\nCollecting sentence_transformers\n  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.4.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.24.7)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-3.3.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install gdown\nimport gdown\n\n# File ID from your link\n!gdown --fuzzy https://drive.google.com/file/d/1STFX5W2vwJVMWeYJ24To95f0sX8Erf_Y/view?usp=sharing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:25:54.105092Z","iopub.execute_input":"2024-12-25T04:25:54.105334Z","iopub.status.idle":"2024-12-25T04:26:01.900340Z","shell.execute_reply.started":"2024-12-25T04:25:54.105314Z","shell.execute_reply":"2024-12-25T04:26:01.899221Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1STFX5W2vwJVMWeYJ24To95f0sX8Erf_Y\nFrom (redirected): https://drive.google.com/uc?id=1STFX5W2vwJVMWeYJ24To95f0sX8Erf_Y&confirm=t&uuid=e3ce1f58-f632-4bfc-b227-391b4e4963dd\nTo: /kaggle/working/train.csv\n100%|█████████████████████████████████████████| 185M/185M [00:01<00:00, 112MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:26:01.902652Z","iopub.execute_input":"2024-12-25T04:26:01.903405Z","iopub.status.idle":"2024-12-25T04:26:05.016732Z","shell.execute_reply.started":"2024-12-25T04:26:01.903379Z","shell.execute_reply":"2024-12-25T04:26:05.015892Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!gdown --fuzzy https://drive.google.com/file/d/1aMTDpcJy5s6iRGQ1LLx9QYUuwOfLUIzv/view?usp=drive_link","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:26:05.018234Z","iopub.execute_input":"2024-12-25T04:26:05.018474Z","iopub.status.idle":"2024-12-25T04:26:26.465293Z","shell.execute_reply.started":"2024-12-25T04:26:05.018455Z","shell.execute_reply":"2024-12-25T04:26:26.464078Z"}},"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1aMTDpcJy5s6iRGQ1LLx9QYUuwOfLUIzv\nFrom (redirected): https://drive.google.com/uc?id=1aMTDpcJy5s6iRGQ1LLx9QYUuwOfLUIzv&confirm=t&uuid=412e45f1-bc70-49e6-adf8-7d302fb1c755\nTo: /kaggle/working/jin-AI.zip\n100%|███████████████████████████████████████| 1.82G/1.82G [00:17<00:00, 106MB/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!unzip /kaggle/working/jin-AI.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:26:26.466474Z","iopub.execute_input":"2024-12-25T04:26:26.466809Z","iopub.status.idle":"2024-12-25T04:26:53.472628Z","shell.execute_reply.started":"2024-12-25T04:26:26.466777Z","shell.execute_reply":"2024-12-25T04:26:53.471501Z"}},"outputs":[{"name":"stdout","text":"Archive:  /kaggle/working/jin-AI.zip\n  inflating: jin-AI/checkpoint-36000/config_sentence_transformers.json  \n  inflating: jin-AI/checkpoint-36000/config.json  \n  inflating: jin-AI/checkpoint-36000/model.safetensors  \n  inflating: jin-AI/checkpoint-36000/tokenizer_config.json  \n  inflating: jin-AI/checkpoint-36000/special_tokens_map.json  \n  inflating: jin-AI/checkpoint-36000/tokenizer.json  \n  inflating: jin-AI/checkpoint-36000/sentence_bert_config.json  \n  inflating: jin-AI/checkpoint-36000/custom_st.py  \n  inflating: jin-AI/checkpoint-36000/modules.json  \n  inflating: jin-AI/checkpoint-36000/README.md  \n  inflating: jin-AI/checkpoint-36000/training_args.bin  \n  inflating: jin-AI/checkpoint-36000/optimizer.pt  \n  inflating: jin-AI/checkpoint-36000/scheduler.pt  \n  inflating: jin-AI/checkpoint-36000/rng_state.pth  \n  inflating: jin-AI/checkpoint-36000/trainer_state.json  \n  inflating: jin-AI/checkpoint-36000/1_Pooling/config.json  \n  inflating: jin-AI/checkpoint-38440/config_sentence_transformers.json  \n  inflating: jin-AI/checkpoint-38440/config.json  \n  inflating: jin-AI/checkpoint-38440/model.safetensors  \n  inflating: jin-AI/checkpoint-38440/tokenizer_config.json  \n  inflating: jin-AI/checkpoint-38440/special_tokens_map.json  \n  inflating: jin-AI/checkpoint-38440/tokenizer.json  \n  inflating: jin-AI/checkpoint-38440/sentence_bert_config.json  \n  inflating: jin-AI/checkpoint-38440/custom_st.py  \n  inflating: jin-AI/checkpoint-38440/modules.json  \n  inflating: jin-AI/checkpoint-38440/README.md  \n  inflating: jin-AI/checkpoint-38440/training_args.bin  \n  inflating: jin-AI/checkpoint-38440/optimizer.pt  \n  inflating: jin-AI/checkpoint-38440/scheduler.pt  \n  inflating: jin-AI/checkpoint-38440/rng_state.pth  \n  inflating: jin-AI/checkpoint-38440/trainer_state.json  \n  inflating: jin-AI/checkpoint-38440/1_Pooling/config.json  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch \nimport torch.nn.functional as F\nfrom sentence_transformers import SentenceTransformer\nimport gc\nfrom tqdm import tqdm\nimport os\n\nfrom transformers import AutoModel, AutoConfig, AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:26:53.473779Z","iopub.execute_input":"2024-12-25T04:26:53.474100Z","iopub.status.idle":"2024-12-25T04:27:10.277507Z","shell.execute_reply.started":"2024-12-25T04:26:53.474071Z","shell.execute_reply":"2024-12-25T04:27:10.276623Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!pip install elasticsearch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:27:10.278425Z","iopub.execute_input":"2024-12-25T04:27:10.279113Z","iopub.status.idle":"2024-12-25T04:27:14.297224Z","shell.execute_reply.started":"2024-12-25T04:27:10.279082Z","shell.execute_reply":"2024-12-25T04:27:14.296235Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting elasticsearch\n  Downloading elasticsearch-8.17.0-py3-none-any.whl.metadata (8.8 kB)\nCollecting elastic-transport<9,>=8.15.1 (from elasticsearch)\n  Downloading elastic_transport-8.15.1-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.2.3)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.8.30)\nDownloading elasticsearch-8.17.0-py3-none-any.whl (571 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.2/571.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: elastic-transport, elasticsearch\nSuccessfully installed elastic-transport-8.15.1 elasticsearch-8.17.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from elasticsearch import Elasticsearch\nes = Elasticsearch(\n    cloud_id=\"154429e62277481486a87de00a5ac969:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJGQ3ODZhN2Q1N2IyMTRjY2ViNWU5MWRmZWNhMDIxNTg3JGIxMzJiZGFjZmZlNTQ3MGJiZGY3MDIwY2MyNWRiNGRm\",\n    api_key=\"S0R5ZC1aTUJ4MW5lOXZRQlh6Y2M6MUpHUU1BWGRSMUtJVmh3dHpuX0hnZw==\"\n)\nif es.ping():\n    print(\"Connected to Elasticsearch\")\nelse:\n    raise ConnectionError(\"Failed to connect to Elasticsearch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:27:14.298171Z","iopub.execute_input":"2024-12-25T04:27:14.298400Z","iopub.status.idle":"2024-12-25T04:27:14.587293Z","shell.execute_reply.started":"2024-12-25T04:27:14.298381Z","shell.execute_reply":"2024-12-25T04:27:14.586587Z"}},"outputs":[{"name":"stdout","text":"Connected to Elasticsearch\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Initialize the model\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nembedding_model_encoding = AutoModel.from_pretrained(\"/kaggle/working/jin-AI/checkpoint-38440\", trust_remote_code=True, use_flash_attn=False)\nembedding_model_encoding = embedding_model_encoding.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:27:14.589390Z","iopub.execute_input":"2024-12-25T04:27:14.589664Z","iopub.status.idle":"2024-12-25T04:27:18.348158Z","shell.execute_reply.started":"2024-12-25T04:27:14.589644Z","shell.execute_reply":"2024-12-25T04:27:18.347373Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"configuration_xlm_roberta.py:   0%|          | 0.00/6.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"560928a277ff41498c534dac9f0caa5c"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- configuration_xlm_roberta.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_lora.py:   0%|          | 0.00/15.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"194f8f6ef50749f6ae93b211955a7b0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_xlm_roberta.py:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ba6d77b393640ddbd5e0028f5f77f61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"xlm_padding.py:   0%|          | 0.00/10.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d24566bafbb74ecd99c7d50f952b00af"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- xlm_padding.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"embedding.py:   0%|          | 0.00/3.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de47b403818049d58e1b5f99c62c56f8"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- embedding.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"rotary.py:   0%|          | 0.00/24.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd36c096afc54f81ae21f6446c8ceef3"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- rotary.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"mha.py:   0%|          | 0.00/34.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f82159f7f9ea4c949952d4a9adb1a71b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- mha.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"mlp.py:   0%|          | 0.00/7.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93f3aed6f0144df9adaca2e069ed5ce"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- mlp.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"block.py:   0%|          | 0.00/17.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a83731533fb543a7af24ca7a54160d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"stochastic_depth.py:   0%|          | 0.00/3.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c9680652ee4445ad7d31caeb2c914b"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- stochastic_depth.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- block.py\n- stochastic_depth.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- modeling_xlm_roberta.py\n- xlm_padding.py\n- embedding.py\n- rotary.py\n- mha.py\n- mlp.py\n- block.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n- modeling_lora.py\n- modeling_xlm_roberta.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\n# Đọc tệp CSV gốc với bỏ qua các dòng từ 1 đến 110000\nfile_path = '/kaggle/working/train.csv'\ntest = pd.read_csv(file_path, skiprows=range(1, 110001))\n\n# Lưu dữ liệu đã đọc vào một tệp CSV mới\noutput_path = '/kaggle/working/new_train.csv'\ntest.to_csv(output_path, index=False)  # index=False để không lưu chỉ mục","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:27:18.349136Z","iopub.execute_input":"2024-12-25T04:27:18.349345Z","iopub.status.idle":"2024-12-25T04:27:20.337452Z","shell.execute_reply.started":"2024-12-25T04:27:18.349328Z","shell.execute_reply":"2024-12-25T04:27:20.336821Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom elasticsearch import Elasticsearch\nimport pandas as pd\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:27:20.338299Z","iopub.execute_input":"2024-12-25T04:27:20.338556Z","iopub.status.idle":"2024-12-25T04:27:20.342544Z","shell.execute_reply.started":"2024-12-25T04:27:20.338532Z","shell.execute_reply":"2024-12-25T04:27:20.341677Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"reranker_tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-m3')\nreranker_model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-v2-m3').to(device)\nreranker_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:27:20.343590Z","iopub.execute_input":"2024-12-25T04:27:20.343901Z","iopub.status.idle":"2024-12-25T04:28:17.056928Z","shell.execute_reply.started":"2024-12-25T04:27:20.343871Z","shell.execute_reply":"2024-12-25T04:28:17.056060Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eaa397ac33741d3ad4efde177232e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"710d1c389968469aa17e6e067325c2ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e49547f7444345fdb3f296731065dcdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e73031d3a2406b9e7b67ae334fea59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/795 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94017c4cff3c4a079964e40ed3a1b3d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a676f21b9d6d4ec984e854c3fe12011d"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"XLMRobertaForSequenceClassification(\n  (roberta): XLMRobertaModel(\n    (embeddings): XLMRobertaEmbeddings(\n      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n      (position_embeddings): Embedding(8194, 1024, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 1024)\n      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): XLMRobertaEncoder(\n      (layer): ModuleList(\n        (0-23): 24 x XLMRobertaLayer(\n          (attention): XLMRobertaAttention(\n            (self): XLMRobertaSelfAttention(\n              (query): Linear(in_features=1024, out_features=1024, bias=True)\n              (key): Linear(in_features=1024, out_features=1024, bias=True)\n              (value): Linear(in_features=1024, out_features=1024, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): XLMRobertaSelfOutput(\n              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): XLMRobertaIntermediate(\n            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): XLMRobertaOutput(\n            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): XLMRobertaClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Kiểm tra số lượng tài liệu trong Elasticsearch\nindex_name = \"jin-ai-1024-da-finedtune\"\nresponse = es.count(index=index_name)\n\n# In ra số lượng tài liệu\nprint(f\"Số lượng tài liệu trong index '{index_name}': {response['count']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T04:29:32.306438Z","iopub.execute_input":"2024-12-25T04:29:32.306709Z","iopub.status.idle":"2024-12-25T04:29:32.346966Z","shell.execute_reply.started":"2024-12-25T04:29:32.306688Z","shell.execute_reply":"2024-12-25T04:29:32.346079Z"}},"outputs":[{"name":"stdout","text":"Số lượng tài liệu trong index 'jin-ai-finetune1': 263254\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/working/new_train.csv')\n\ncount = 0\nindex_name = \"jin-ai-finetune1\"\n\ncount = 0\nwith open(\"predict_reranked.txt\", \"w\") as f:\n    for _, row in test.iterrows():\n        qid = row['qid']\n        question = row['question']\n\n        # Mã hóa câu hỏi thành vector (dense embedding)\n        dense = embedding_model_encoding.encode(question, task=\"text-matching\")  # encode_batch là hàm mã hóa câu hỏi thành vector\n\n        # Truy vấn chỉ sử dụng cosine similarity cho dense vector\n        count += 1\n        print(f\"Processing query {count}/{len(test)}\")\n        query_body = {\n            \"query\": {\n                \"script_score\": {\n                    \"query\": {\n                        \"match_all\": {}\n                    },\n                    \"script\": {\n                        \"source\": \"cosineSimilarity(params.query_vector, 'dense_embeddings') + 1.0\",\n                        \"params\": {\n                            \"query_vector\": dense.reshape(-1).tolist()\n                        }\n                    }\n                }\n            },\n            \"size\": 10  # Trả về top 10 kết quả từ Elasticsearch\n        }\n\n        # Thực hiện truy vấn Elasticsearch\n        response = es.search(index='jin-ai-finetune-last5', body=query_body,request_timeout=120)\n\n        # Lấy danh sách tài liệu và nội dung\n        retrived_docs = [doc[\"_source\"][\"text\"] for doc in response['hits']['hits']]\n\n        # **Giai đoạn rerank**\n        # Form query-chunk pairs cho mô hình rerank\n        pairs = [[question, text] for text in retrived_docs]\n\n        # Tokenize input và gửi qua mô hình rerank\n        with torch.no_grad():\n            inputs = reranker_tokenizer(\n                pairs,\n                padding=True,\n                truncation=True,\n                return_tensors=\"pt\"\n            ).to(device)\n\n            scores = reranker_model(**inputs, return_dict=True).logits.view(-1).float()\n\n        # Kết hợp tài liệu với điểm rerank\n        reranked_results = [\n            {\"cid\": response['hits']['hits'][i][\"_source\"][\"cid\"], \"rerank_score\": score.item()}\n            for i, score in enumerate(scores)\n        ]\n\n        # Sắp xếp lại theo rerank_score\n        reranked_results = sorted(reranked_results, key=lambda x: x['rerank_score'], reverse=True)\n\n        # Ghi qid và các cid vào file\n        f.write(f\"{qid} \")\n        f.write(\" \".join([str(result[\"cid\"]) for result in reranked_results]))\n        f.write(\"\\n\")\n\nprint(\"Truy vấn và ghi file predict_reranked.txt đã hoàn tất.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}